{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import numpy as np\n",
    "from numpy import radians, sin, cos, arccos \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.stats import zscore\n",
    "import h3\n",
    "from scipy.stats import entropy\n",
    "import hashlib\n",
    "from math import radians, cos, sin, asin, sqrt \n",
    "import folium "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw_data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['amount_log'] = np.log1p(df['amount'])\n",
    "df['population_log'] = np.log1p(df['population_city'])\n",
    "df['amount_per_person'] = df['amount'] / (df['population_city']) \n",
    "df['amount_per_person'].replace([np.inf, -np.inf], 0, inplace=True) \n",
    "df['transaction_time'] = pd.to_datetime(df['transaction_time'])\n",
    "df['hour'] = df['transaction_time'].dt.hour\n",
    "df['weekday'] = df['transaction_time'].dt.weekday\n",
    "df['is_night'] = df['hour'].apply(lambda h: 1 if h < 6 or h > 22 else 0)\n",
    "df['user_id'] = (\n",
    "    df['name_1'].astype(str) + '_' + df['name_2'] + '_' + df['street']\n",
    ").map(lambda x: hashlib.md5(x.encode()).hexdigest())\n",
    "\n",
    "df = df.sort_values('transaction_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(len(df) * 0.8)\n",
    "train = df.iloc[:split_point].copy()\n",
    "test = df.iloc[split_point:].copy()\n",
    "\n",
    "transactions_ok = train[train[\"target\"] == 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = transactions_ok.groupby([\"user_id\", \"cat_id\"])[\"amount\"].agg(\n",
    "    mean_amount=\"mean\",\n",
    "    median_amount=\"median\",\n",
    "    std_amount=\"std\",\n",
    "    p95_amount=lambda x: x.quantile(0.95),\n",
    "    count=\"count\"\n",
    ").reset_index()\n",
    "\n",
    "mean_pivot = grouped.pivot(index=\"user_id\", columns=\"cat_id\", values=\"mean_amount\").add_prefix(\"mean_cat_\")\n",
    "median_pivot = grouped.pivot(index=\"user_id\", columns=\"cat_id\", values=\"median_amount\").add_prefix(\"median_cat_\")\n",
    "std_pivot = grouped.pivot(index=\"user_id\", columns=\"cat_id\", values=\"std_amount\").add_prefix(\"std_cat_\")\n",
    "p95_pivot = grouped.pivot(index=\"user_id\", columns=\"cat_id\", values=\"p95_amount\").add_prefix(\"p95_cat_\")\n",
    "count_pivot = grouped.pivot(index=\"user_id\", columns=\"cat_id\", values=\"count\").add_prefix(\"count_cat_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = pd.concat(\n",
    "    [mean_pivot, median_pivot, std_pivot, p95_pivot, count_pivot],\n",
    "    axis=1\n",
    ").reset_index()\n",
    "profile_df = profile_df.fillna(0)\n",
    "\n",
    "profile_pivot = grouped.rename(columns={ \n",
    "    'mean_amount': 'user_cat_mean_amount',\n",
    "    'median_amount': 'user_cat_median_amount',\n",
    "    'std_amount': 'user_cat_std_amount',\n",
    "    'p95_amount': 'user_cat_p95_amount',\n",
    "    'count': 'user_cat_txn_count_in_profile'\n",
    "}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions_ok_with_profile = transactions_ok.merge(\n",
    "    profile_pivot[['user_id', 'cat_id', 'user_cat_mean_amount', 'user_cat_median_amount', 'user_cat_std_amount', 'user_cat_p95_amount']],\n",
    "    on=['user_id', 'cat_id'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "transactions_ok_with_profile['z_score'] = (\n",
    "    (transactions_ok_with_profile['amount'] - transactions_ok_with_profile['user_cat_mean_amount']) / transactions_ok_with_profile['user_cat_std_amount']\n",
    ")\n",
    "transactions_ok_with_profile['delta_from_median'] = (\n",
    "    transactions_ok_with_profile['amount'] - transactions_ok_with_profile['user_cat_median_amount']\n",
    ")\n",
    "transactions_ok_with_profile['above_p95'] = (\n",
    "    transactions_ok_with_profile['amount'] > transactions_ok_with_profile['user_cat_p95_amount']\n",
    ").astype(int)\n",
    "\n",
    "transactions_ok_with_profile['z_score'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "transactions_ok_with_profile['z_score'].fillna(0, inplace=True)\n",
    "transactions_ok_with_profile['delta_from_median'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation_profile = (\n",
    "    transactions_ok_with_profile \n",
    "    .groupby('user_id')\n",
    "    .agg(\n",
    "        mean_z_score=('z_score', 'mean'),\n",
    "        std_z_score=('z_score', 'std'),\n",
    "        p95_z_score=('z_score', lambda x: np.percentile(x.dropna(), 95) if not x.dropna().empty else 0), # Добавлена обработка пустых серий\n",
    "        frac_above_p95=('above_p95', 'mean'),\n",
    "        mean_delta_from_median=('delta_from_median', 'mean'),\n",
    "        std_delta_from_median=('delta_from_median', 'std'),\n",
    "    )\n",
    "    .reset_index()\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = (\n",
    "    profile_df\n",
    "    .merge(deviation_profile, on='user_id', how='left')\n",
    "    .fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_pivot = transactions_ok.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='weekday',\n",
    "    values='transaction_time',\n",
    "    aggfunc='count'\n",
    ").fillna(0)\n",
    "weekday_pivot.columns = [f'weekday_count_{col}' for col in weekday_pivot.columns]\n",
    "weekday_pivot = weekday_pivot.reset_index()\n",
    "\n",
    "hour_pivot = transactions_ok.pivot_table(\n",
    "    index='user_id',\n",
    "    columns='hour',\n",
    "    values='transaction_time',\n",
    "    aggfunc='count'\n",
    ").fillna(0)\n",
    "hour_pivot.columns = [f'hour_count_{col}' for col in hour_pivot.columns]\n",
    "hour_pivot = hour_pivot.reset_index()\n",
    "\n",
    "profile_df = profile_df.merge(weekday_pivot, on='user_id', how='left').fillna(0) \n",
    "profile_df = profile_df.merge(hour_pivot, on='user_id', how='left').fillna(0)    \n",
    "\n",
    "txn_counts = transactions_ok.groupby('user_id').size().rename('txn_count').reset_index()\n",
    "profile_df = profile_df.merge(txn_counts, on='user_id', how='left').fillna(0) \n",
    "\n",
    "weekday_cols = [col for col in profile_df.columns if col.startswith('weekday_count_')]\n",
    "hour_cols = [col for col in profile_df.columns if col.startswith('hour_count_')]\n",
    "\n",
    "\n",
    "for col in weekday_cols + hour_cols:\n",
    "    profile_df[col] = np.where(profile_df['txn_count'] > 0, profile_df[col] / profile_df['txn_count'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "user_coords = transactions_ok.groupby('user_id').agg(\n",
    "    mean_lat=('lat', 'mean'),\n",
    "    mean_lon=('lon', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "transactions_ok_with_user_coords = transactions_ok.merge(user_coords, on='user_id', how='left')\n",
    "\n",
    "transactions_ok_with_user_coords['geo_distance'] = transactions_ok_with_user_coords.apply(\n",
    "    lambda row: haversine(row['lat'], row['lon'], row['mean_lat'], row['mean_lon'])\n",
    "    if pd.notnull(row['mean_lat']) and pd.notnull(row['mean_lon']) else np.nan, \n",
    "    axis=1\n",
    ")\n",
    "transactions_ok_with_user_coords['geo_distance'].fillna(0, inplace=True) \n",
    "\n",
    "geo_profile = transactions_ok_with_user_coords.groupby('user_id').agg(\n",
    "    mean_geo_distance=('geo_distance', 'mean'),\n",
    "    max_geo_distance=('geo_distance', 'max'),\n",
    "    std_geo_distance=('geo_distance', 'std'),\n",
    "    geo_unique_locations=('lat', lambda x: pd.Series(list(zip(x, transactions_ok_with_user_coords.loc[x.index, 'lon']))).nunique()) \n",
    ").reset_index().fillna(0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_df = profile_df.merge(geo_profile, on='user_id', how='left').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_coords_for_merge = user_coords.rename(columns={\n",
    "    'mean_lat': 'user_profile_mean_lat',\n",
    "    'mean_lon': 'user_profile_mean_lon'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transaction_deviation_features(df, profile_pivot_ref, user_coords_ref):\n",
    "    df_enriched = df.copy()\n",
    "\n",
    "    df_enriched = df_enriched.merge(\n",
    "        profile_pivot_ref[['user_id', 'cat_id', 'user_cat_mean_amount', 'user_cat_median_amount', 'user_cat_std_amount', 'user_cat_p95_amount']],\n",
    "        on=['user_id', 'cat_id'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    df_enriched['txn_z_score_vs_user_cat'] = \\\n",
    "        (df_enriched['amount'] - df_enriched['user_cat_mean_amount']) / df_enriched['user_cat_std_amount']\n",
    "    df_enriched['txn_delta_vs_user_cat_median'] = \\\n",
    "        df_enriched['amount'] - df_enriched['user_cat_median_amount']\n",
    "    df_enriched['txn_above_user_cat_p95'] = \\\n",
    "        (df_enriched['amount'] > df_enriched['user_cat_p95_amount']).astype(int)\n",
    "    df_enriched['txn_z_score_vs_user_cat'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    fill_zero_cols = [\n",
    "        'user_cat_mean_amount', 'user_cat_median_amount', 'user_cat_std_amount', 'user_cat_p95_amount',\n",
    "        'txn_z_score_vs_user_cat', 'txn_delta_vs_user_cat_median'\n",
    "    ]\n",
    "    for col in fill_zero_cols:\n",
    "        df_enriched[col].fillna(0, inplace=True)\n",
    "\n",
    "    df_enriched['txn_above_user_cat_p95'] = \\\n",
    "        (df_enriched['amount'] > df_enriched['user_cat_p95_amount']).astype(int)\n",
    "\n",
    "\n",
    "    df_enriched = df_enriched.merge(\n",
    "        user_coords_for_merge[['user_id', 'user_profile_mean_lat', 'user_profile_mean_lon']],\n",
    "        on='user_id',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    df_enriched['txn_distance_from_user_home_base'] = df_enriched.apply(\n",
    "        lambda row: haversine(row['lat'], row['lon'], row['user_profile_mean_lat'], row['user_profile_mean_lon'])\n",
    "        if pd.notnull(row['user_profile_mean_lat']) and pd.notnull(row['user_profile_mean_lon']) and pd.notnull(row['lat']) and pd.notnull(row['lon'])\n",
    "        else np.nan,\n",
    "        axis=1\n",
    "    )\n",
    "   \n",
    "    df_enriched['txn_distance_from_user_home_base'].fillna(\n",
    "        df_enriched['txn_distance_from_user_home_base'].median(), inplace=True \n",
    "    )\n",
    "    df_enriched['txn_distance_from_user_home_base'].fillna(0, inplace=True) \n",
    "    \n",
    "    return df_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_transaction_deviation_features(train, profile_pivot, user_coords_for_merge)\n",
    "test = create_transaction_deviation_features(test, profile_pivot, user_coords_for_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.merge(profile_df.add_prefix('user_profile_'), left_on='user_id', right_on='user_profile_user_id', how='left')\n",
    "test = test.merge(profile_df.add_prefix('user_profile_'), left_on='user_id', right_on='user_profile_user_id', how='left')\n",
    "\n",
    "if 'user_profile_user_id' in train.columns:\n",
    "    train.drop(columns=['user_profile_user_id'], inplace=True)\n",
    "if 'user_profile_user_id' in test.columns:\n",
    "    test.drop(columns=['user_profile_user_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_cols_in_final_df = [col for col in train.columns if col.startswith('user_profile_')]\n",
    "train[profile_cols_in_final_df] = train[profile_cols_in_final_df].fillna(0)\n",
    "test[profile_cols_in_final_df] = test[profile_cols_in_final_df].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('train_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('test_clean.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
